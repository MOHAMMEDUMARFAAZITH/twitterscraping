
# Twitter Scraping
# Problem Statement:

Today, data is scattered everywhere in the world. Especially in social media, there may be a big quantity of data on Facebook, Instagram, Youtube, Twitter, etc. This consists of pictures and films on Youtube and Instagram as compared to Facebook and Twitter. To get the real facts on Twitter, you want to scrape the data from Twitter. You Need to Scrape the data like (date, id, url, tweet content, user,reply count, retweet count,language, source, like count etc) from twitter.

# Project Title:  Twitter Scraping

# Domain:  Social Media

# Skills take away From This Project:

   1. Python scripting
   2. Data Collection
   3. MongoDB
   4. Streamlit



# Installations:

    pip install streamlit
Streamlit is an open source app framework in Python language. It helps us create web apps for data science and machine learning in a short time. It is compatible with major Python libraries such as scikit-learn, Keras, PyTorch, SymPy(latex), NumPy, pandas, Matplotlib etc

    pip install datetime

The datetime module supplies classes for manipulating dates and times
    pip install snscrape

Snscrape does not require API key to access it. There is also no limit to the number of tweets you can get.
snscrape - social networking services (SNS). 
which is fetch data like user profiles, hashtags, or searches and returns the discovered items.

    pip install pandas

Pandas is a Python library used for working with data sets. It has functions for analyzing, cleaning, exploring, and manipulating data.

    pip install pymongo
    
PyMongo is MongoDB's official native driver for Python. It's a library that lets you connect to a MongoDB database and query the data stored using the MongoDB Query API. It is the recommended way to interface with the document database.

# Procedure:
In GUI using Streamlit

Step 1 - Select a keyword or Hashtag.

Step 2 - Enter your scraped word.

Step 3 - Select the starting date.

Step 4 - Select the end date.

Step 5 - Enter your tweet count.

# There are four features available in this page 

1. Show dataframe.

2. Upload dataframe into mongodb database.

3. Download dataframe as csv format.

4. Download dataframe as json format.

# Results:

You have to build a solution that should be able to scrape the twitter data and store that in the database and allow the user to download the data with multiple data formats.
## API Reference

https://docs.streamlit.io/library/api-reference




## Documentation

https://pandas.pydata.org/docs/

https://api.mongodb.com/python/3.3.1/tutorial.html
## ðŸš€ About Me
I'm a Data Science student...


## Author

https://github.com/MOHAMMEDUMARFAAZITH
